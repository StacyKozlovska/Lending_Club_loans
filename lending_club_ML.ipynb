{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc82e8a-409e-43ce-9f65-71f23075e526",
   "metadata": {},
   "source": [
    "# Lending Club Dataset:\n",
    "# ML Model Training, Tuning, and Deployment - Notebook 2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ad8ef-6db5-4559-9e4d-676c15ca347a",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    "- Create a preprocessing Pipeline\n",
    "- Create baseline models\n",
    "- Build three models to:\n",
    "    - classify loans into \"accept/reject\";\n",
    "    - predict the grade of the loan;\n",
    "    - predict the sub-grade and interest rate of the loan.\n",
    "- Perform model selection, tune hyperparameters for the best-performing models, and test those models.\n",
    "- Deploy the models to Google Cloud Platform.\n",
    "\n",
    "## Additional Notes:\n",
    "- The main performance metrics for classification tasks are ROC-AUC(for initial model selection) and F2 since we want to catch most potentially problematic loans, but also avoid flagging too many good loans and performing too much costly additional assessment. Ideally, this metric should be discussed with the client beforehand.\n",
    "- The main performance metric for regression tasks is R2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "4cdbae0c-daef-41b9-b1bc-63f834ed0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import openpyxl\n",
    "import re\n",
    "import textwrap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, explained_variance_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "import shap\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tpot import TPOTClassifier, TPOTRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "import joblib\n",
    "import dill\n",
    "\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e292f7-ff31-48ad-96ef-4bdf278518ee",
   "metadata": {},
   "source": [
    "# 1. Preprocessing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0b3987e8-157a-45e6-8a5b-eacd88aa634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_data = pd.read_csv('accepted_cleaned_reduced.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "db5e749e-ada7-4abc-9584-14b76b62910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>avg_cur_bal</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
       "      <th>mo_sin_rcnt_tl</th>\n",
       "      <th>mort_acc</th>\n",
       "      <th>mths_since_recent_bc</th>\n",
       "      <th>mths_since_recent_inq</th>\n",
       "      <th>num_accts_ever_120_pd</th>\n",
       "      <th>num_actv_bc_tl</th>\n",
       "      <th>num_il_tl</th>\n",
       "      <th>num_rev_accts</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>term_months</th>\n",
       "      <th>emp_length_years</th>\n",
       "      <th>emp_length_numeric</th>\n",
       "      <th>fico_range_avg</th>\n",
       "      <th>utilization_rate</th>\n",
       "      <th>delinquent</th>\n",
       "      <th>high_utilization</th>\n",
       "      <th>last_fico_range_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68407277</th>\n",
       "      <td>3600</td>\n",
       "      <td>13.99</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>PA</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>4</td>\n",
       "      <td>20701.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>13734.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>36</td>\n",
       "      <td>10+</td>\n",
       "      <td>10</td>\n",
       "      <td>677.0</td>\n",
       "      <td>1.252104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68355089</th>\n",
       "      <td>24700</td>\n",
       "      <td>11.99</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>small_business</td>\n",
       "      <td>SD</td>\n",
       "      <td>16.06</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21470.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9733.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>97.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79300.0</td>\n",
       "      <td>24667.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>36</td>\n",
       "      <td>10+</td>\n",
       "      <td>10</td>\n",
       "      <td>717.0</td>\n",
       "      <td>1.410724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68476807</th>\n",
       "      <td>10400</td>\n",
       "      <td>22.45</td>\n",
       "      <td>F</td>\n",
       "      <td>F1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>104433</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>PA</td>\n",
       "      <td>25.37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21929.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>27644.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128</td>\n",
       "      <td>210</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>96.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20300.0</td>\n",
       "      <td>88097.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>60</td>\n",
       "      <td>1-3</td>\n",
       "      <td>3</td>\n",
       "      <td>697.0</td>\n",
       "      <td>1.201364</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68476668</th>\n",
       "      <td>20000</td>\n",
       "      <td>9.17</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>180000</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>MN</td>\n",
       "      <td>14.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>87329.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30030.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "      <td>306</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>46452.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>36</td>\n",
       "      <td>10+</td>\n",
       "      <td>10</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1.217607</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67275481</th>\n",
       "      <td>20000</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B</td>\n",
       "      <td>B1</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>85000</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>SC</td>\n",
       "      <td>17.61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>36144.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>36</td>\n",
       "      <td>10+</td>\n",
       "      <td>10</td>\n",
       "      <td>707.0</td>\n",
       "      <td>0.998249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loan_amnt  int_rate grade sub_grade home_ownership  annual_inc  \\\n",
       "id                                                                         \n",
       "68407277       3600     13.99     C        C4       MORTGAGE       55000   \n",
       "68355089      24700     11.99     C        C1       MORTGAGE       65000   \n",
       "68476807      10400     22.45     F        F1       MORTGAGE      104433   \n",
       "68476668      20000      9.17     B        B2       MORTGAGE      180000   \n",
       "67275481      20000      8.49     B        B1       MORTGAGE       85000   \n",
       "\n",
       "         verification_status loan_status             purpose addr_state  \\\n",
       "id                                                                        \n",
       "68407277        Not Verified  Fully Paid  debt_consolidation         PA   \n",
       "68355089        Not Verified  Fully Paid      small_business         SD   \n",
       "68476807     Source Verified  Fully Paid      major_purchase         PA   \n",
       "68476668        Not Verified  Fully Paid  debt_consolidation         MN   \n",
       "67275481        Not Verified  Fully Paid      major_purchase         SC   \n",
       "\n",
       "            dti  delinq_2yrs  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
       "id                                                                           \n",
       "68407277   5.91            0               1         7        0     2765.0   \n",
       "68355089  16.06            1               4        22        0    21470.0   \n",
       "68476807  25.37            1               3        12        0    21929.0   \n",
       "68476668  14.67            0               0        12        0    87329.0   \n",
       "67275481  17.61            1               0         8        0      826.0   \n",
       "\n",
       "         initial_list_status  collections_12_mths_ex_med application_type  \\\n",
       "id                                                                          \n",
       "68407277                   w                           0       Individual   \n",
       "68355089                   w                           0       Individual   \n",
       "68476807                   w                           0       Individual   \n",
       "68476668                   f                           0       Individual   \n",
       "67275481                   w                           0       Individual   \n",
       "\n",
       "          acc_now_delinq  tot_coll_amt  acc_open_past_24mths  avg_cur_bal  \\\n",
       "id                                                                          \n",
       "68407277               0         722.0                     4      20701.0   \n",
       "68355089               0           0.0                     4       9733.0   \n",
       "68476807               0           0.0                    10      27644.0   \n",
       "68476668               0           0.0                     6      30030.0   \n",
       "67275481               0           0.0                     4      17700.0   \n",
       "\n",
       "          chargeoff_within_12_mths  delinq_amnt  mo_sin_old_il_acct  \\\n",
       "id                                                                    \n",
       "68407277                         0          0.0                 148   \n",
       "68355089                         0          0.0                 113   \n",
       "68476807                         0          0.0                 128   \n",
       "68476668                         0          0.0                 142   \n",
       "67275481                         0          0.0                 149   \n",
       "\n",
       "          mo_sin_old_rev_tl_op  mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl  \\\n",
       "id                                                                      \n",
       "68407277                   128                      3               3   \n",
       "68355089                   192                      2               2   \n",
       "68476807                   210                      4               4   \n",
       "68476668                   306                     10              10   \n",
       "67275481                    55                     32              13   \n",
       "\n",
       "          mort_acc  mths_since_recent_bc  mths_since_recent_inq  \\\n",
       "id                                                                \n",
       "68407277         1                     4                      4   \n",
       "68355089         4                     2                      0   \n",
       "68476807         6                     4                      1   \n",
       "68476668         4                    12                     10   \n",
       "67275481         3                    32                      8   \n",
       "\n",
       "          num_accts_ever_120_pd  num_actv_bc_tl  num_il_tl  num_rev_accts  \\\n",
       "id                                                                          \n",
       "68407277                      2               2          3              9   \n",
       "68355089                      0               5          6             27   \n",
       "68476807                      0               4         10             19   \n",
       "68476668                      0               4          7             16   \n",
       "67275481                      1               2          9              3   \n",
       "\n",
       "          num_tl_120dpd_2m  num_tl_30dpd  num_tl_90g_dpd_24m  \\\n",
       "id                                                             \n",
       "68407277                 0             0                   0   \n",
       "68355089                 0             0                   0   \n",
       "68476807                 0             0                   0   \n",
       "68476668                 0             0                   0   \n",
       "67275481                 0             0                   1   \n",
       "\n",
       "          num_tl_op_past_12m  pct_tl_nvr_dlq  pub_rec_bankruptcies  tax_liens  \\\n",
       "id                                                                              \n",
       "68407277                   3            76.9                     0          0   \n",
       "68355089                   2            97.4                     0          0   \n",
       "68476807                   4            96.6                     0          0   \n",
       "68476668                   2            96.3                     0          0   \n",
       "67275481                   0            93.3                     0          0   \n",
       "\n",
       "          total_bc_limit  total_il_high_credit_limit disbursement_method  \\\n",
       "id                                                                         \n",
       "68407277          2400.0                     13734.0                Cash   \n",
       "68355089         79300.0                     24667.0                Cash   \n",
       "68476807         20300.0                     88097.0                Cash   \n",
       "68476668         31500.0                     46452.0                Cash   \n",
       "67275481         14500.0                     36144.0                Cash   \n",
       "\n",
       "          term_months emp_length_years  emp_length_numeric  fico_range_avg  \\\n",
       "id                                                                           \n",
       "68407277           36              10+                  10           677.0   \n",
       "68355089           36              10+                  10           717.0   \n",
       "68476807           60              1-3                   3           697.0   \n",
       "68476668           36              10+                  10           682.0   \n",
       "67275481           36              10+                  10           707.0   \n",
       "\n",
       "          utilization_rate  delinquent  high_utilization  last_fico_range_avg  \n",
       "id                                                                             \n",
       "68407277          1.252104           0                 0                562.0  \n",
       "68355089          1.410724           0                 0                697.0  \n",
       "68476807          1.201364           0                 1                702.0  \n",
       "68476668          1.217607           0                 1                652.0  \n",
       "67275481          0.998249           0                 0                672.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7b64355d-2ba4-45ec-8376-99066266b7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "Charged Off    195388\n",
       "Fully Paid     790623\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_data_filtered = accepted_data[accepted_data['loan_status'].isin(['Fully Paid', 'Charged Off'])]\n",
    "\n",
    "accepted_data_filtered.groupby('loan_status').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "33248537-3f50-401f-8b6d-ee1fdee7f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_status\n",
      "Charged Off    195388\n",
      "Fully Paid     195388\n",
      "dtype: int64\n",
      "loan_status\n",
      "Charged Off    5000\n",
      "Fully Paid     5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fully_paid = accepted_data_filtered[accepted_data_filtered['loan_status']=='Fully Paid']\n",
    "charged_off = accepted_data_filtered[accepted_data_filtered['loan_status']=='Charged Off']\n",
    "\n",
    "fully_paid_undersampled = resample(fully_paid, replace=False,  \n",
    "                                  n_samples=len(charged_off), \n",
    "                                  random_state=123)\n",
    "\n",
    "balanced_data = pd.concat([charged_off, fully_paid_undersampled])\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1) \n",
    "\n",
    "print(balanced_data.groupby('loan_status').size())\n",
    "\n",
    "sampled_data = balanced_data.groupby('loan_status').apply(lambda x: x.sample(n=5000, random_state=42)).reset_index(drop=True)\n",
    "print(sampled_data.groupby('loan_status').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "f012bbe0-cc55-4452-8564-939d50b0bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sampled_data.drop(['loan_status', 'grade', 'sub_grade', 'int_rate'], axis=1)\n",
    "y_loan_status = sampled_data['loan_status']\n",
    "y_grade = sampled_data['grade']\n",
    "y_sub_grade = sampled_data['sub_grade']\n",
    "y_int_rate = sampled_data['int_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "8d3afa5e-bbee-470f-a9f1-99619d874501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols = ['emp_length_years']\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "non_ordinal_cols = X.select_dtypes(exclude=['int64', 'float64']).columns.tolist()\n",
    "non_ordinal_cols = [col for col in non_ordinal_cols if col not in ordinal_cols]\n",
    "\n",
    "emp_length_mapping = {'<1': 1, '1-3': 2, '4-6': 3, '7-9': 4, '10+': 5}\n",
    "\n",
    "def map_emp_length(X):\n",
    "    X['emp_length_years'] = X['emp_length_years'].map(emp_length_mapping)\n",
    "    return X\n",
    "\n",
    "emp_length_transformer = FunctionTransformer(map_emp_length, validate=False)\n",
    "\n",
    "addr_state_categories = ['PA', 'SD', 'MN', 'SC', 'RI', 'CA', 'VA', \n",
    "                         'AZ', 'MD', 'NY', 'TX', 'KS', 'NM', 'AL', \n",
    "                         'WA', 'OH', 'GA', 'IL', 'FL', 'CO', 'IN', \n",
    "                         'MI', 'MO', 'DC', 'MA', 'WI', 'NJ', 'DE', \n",
    "                         'TN', 'NH', 'NE', 'OR', 'NC', 'AR', 'NV', \n",
    "                         'WV', 'LA', 'HI', 'WY', 'KY', 'OK', 'CT', \n",
    "                         'VT', 'MS', 'UT', 'ND', 'ME', 'AK', 'MT', \n",
    "                         'ID', 'IA']\n",
    "\n",
    "\n",
    "preprocessor_features = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', MinMaxScaler(), numeric_cols),\n",
    "        ('emp_length_years', emp_length_transformer, ['emp_length_years']),\n",
    "        ('non_ordinal', OneHotEncoder(handle_unknown='ignore', \n",
    "                                      drop='first'), non_ordinal_cols),\n",
    "    ], \n",
    "    remainder='passthrough',\n",
    ")\n",
    "\n",
    "encoding_order = {\n",
    "    'loan_status': None,  \n",
    "    'grade': ['A', 'B', 'C', 'D', 'E', 'F', 'G'],\n",
    "    'sub_grade': ['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5',\n",
    "                  'C1', 'C2', 'C3', 'C4', 'C5', 'D1', 'D2', 'D3', 'D4', 'D5',\n",
    "                  'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
    "                  'G1', 'G2', 'G3', 'G4', 'G5'],\n",
    "    'int_rate': None  \n",
    "}\n",
    "\n",
    "preprocessor_targets = {}\n",
    "for target, order in encoding_order.items():\n",
    "    if target == 'loan_status':\n",
    "        preprocessor_targets[target] = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "    elif order is None:\n",
    "        preprocessor_targets[target] = MinMaxScaler()\n",
    "    else:\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.classes_ = order\n",
    "        preprocessor_targets[target] = label_encoder\n",
    "\n",
    "preprocessor_feature_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_features)\n",
    "])\n",
    "\n",
    "preprocessor_target_pipeline = ColumnTransformer(\n",
    "    transformers=[(target, preprocessor, [target]) for target, \n",
    "                  preprocessor in preprocessor_targets.items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "db09002f-7ffd-42d2-b131-a242a0bcc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stratified_split(X, y, target_column, test_size=0.2, random_state=42,\n",
    "                             stratify=True):\n",
    "    if stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state,\n",
    "        )\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train_status, X_test_status, y_train_status, y_test_status = perform_stratified_split(\n",
    "    X, y_loan_status, 'loan_status'\n",
    ")\n",
    "\n",
    "X_train_grade, X_test_grade, y_train_grade, y_test_grade = perform_stratified_split(\n",
    "    X, y_grade, 'grade'\n",
    ")\n",
    "\n",
    "X_train_sub_grade, X_test_sub_grade, y_train_sub_grade, y_test_sub_grade = perform_stratified_split(\n",
    "    X, y_sub_grade, 'sub_grade',\n",
    ")\n",
    "\n",
    "X_train_int_rate, X_test_int_rate, y_train_int_rate, y_test_int_rate = perform_stratified_split(\n",
    "    X, y_int_rate, 'int_rate', stratify=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "9e00f863-c2be-4896-92fd-b4265d3d09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.preprocessing._encoders\")\n",
    "\n",
    "X_train_all_p = preprocessor_feature_pipeline.fit_transform(X)\n",
    "\n",
    "X_train_status_p = preprocessor_feature_pipeline.transform(X_train_status)\n",
    "X_train_grade_p = preprocessor_feature_pipeline.transform(X_train_grade)\n",
    "X_train_sub_grade_p = preprocessor_feature_pipeline.transform(X_train_sub_grade)\n",
    "X_train_int_rate_p = preprocessor_feature_pipeline.transform(X_train_int_rate)\n",
    "\n",
    "X_test_status_p = preprocessor_feature_pipeline.transform(X_test_status)\n",
    "X_test_grade_p = preprocessor_feature_pipeline.transform(X_test_grade)\n",
    "X_test_sub_grade_p = preprocessor_feature_pipeline.transform(X_test_sub_grade)\n",
    "X_test_int_rate_p = preprocessor_feature_pipeline.transform(X_test_int_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "d70683a7-5164-4f70-bdaf-f2385fd67e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_status_reshaped = np.array(y_train_status).reshape(-1, 1)\n",
    "y_train_status_p = preprocessor_targets['loan_status'].fit_transform(y_train_status_reshaped)\n",
    "y_test_status_reshaped = np.array(y_test_status).reshape(-1, 1)\n",
    "y_test_status_p = preprocessor_targets['loan_status'].transform(y_test_status_reshaped)\n",
    "\n",
    "y_train_grade_p = preprocessor_targets['grade'].fit_transform(y_train_grade)\n",
    "y_test_grade_p = preprocessor_targets['grade'].transform(y_test_grade)\n",
    "\n",
    "y_train_sub_grade_p = preprocessor_targets['sub_grade'].fit_transform(y_train_sub_grade)\n",
    "y_test_sub_grade_p = preprocessor_targets['sub_grade'].transform(y_test_sub_grade)\n",
    "\n",
    "\n",
    "y_train_int_rate_reshaped = y_train_int_rate.values.reshape(-1, 1)\n",
    "y_train_int_rate_p = preprocessor_targets['int_rate'].fit_transform(y_train_int_rate_reshaped)\n",
    "y_test_int_rate_reshaped = y_test_int_rate.values.reshape(-1, 1)\n",
    "y_test_int_rate_p = preprocessor_targets['int_rate'].transform(y_test_int_rate_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "6ed967d7-c7b6-4a8b-b9a2-d24ee2ea8aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor_feature_pipeline.joblib']"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(preprocessor_feature_pipeline, 'preprocessor_feature_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee0283-4c7b-41c3-944b-183b23413ae0",
   "metadata": {},
   "source": [
    "# 2. Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cca82-681e-4612-8aff-247ef8397511",
   "metadata": {},
   "source": [
    "## 2.1. Baseline Model for Loan Status Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "38b833bc-b001-425a-a03d-a564ac7d9e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67      1000\n",
      "         1.0       1.00      0.00      0.00      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.75      0.50      0.33      2000\n",
      "weighted avg       0.75      0.50      0.33      2000\n",
      "\n",
      "F2 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "baseline_classifier = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "baseline_classifier.fit(X_train_status_p, y_train_status_p)\n",
    "\n",
    "baseline_preds = baseline_classifier.predict(X_test_status_p)\n",
    "print(\"Baseline Classification Report:\\n\", classification_report(y_test_status_p, \n",
    "                                                                 baseline_preds, \n",
    "                                                                 zero_division=1))\n",
    "\n",
    "f2 = fbeta_score(y_test_status_p, baseline_preds, beta=2)\n",
    "roc_auc = roc_auc_score(y_test_status_p, baseline_preds)\n",
    "print(f\"F2 Score: {f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1883648-71a3-4eb1-865f-27aa9e52073f",
   "metadata": {},
   "source": [
    "## 2.2. Baseline Model for Grade Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "daac271c-b368-49f6-b752-a55fac491ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Squared Error for Grade Prediction: 1.8264790000000002\n",
      "R-squared (R2): 0.0\n"
     ]
    }
   ],
   "source": [
    "baseline_regressor_grade = DummyRegressor(strategy='mean')\n",
    "\n",
    "baseline_regressor_grade.fit(X_train_grade_p, y_train_grade_p)\n",
    "\n",
    "baseline_preds_grade = baseline_regressor_grade.predict(X_test_grade_p)\n",
    "print(\"Baseline Mean Squared Error for Grade Prediction:\", mean_squared_error(y_test_grade_p, \n",
    "                                                                              baseline_preds_grade))\n",
    "\n",
    "r2 = r2_score(y_test_grade_p, baseline_preds_grade)\n",
    "print(f'R-squared (R2): {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "c6e58ad5-61e4-4fd3-91c6-c57781542356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.11      0.11       240\n",
      "           1       0.26      0.27      0.27       506\n",
      "           2       0.28      0.28      0.28       600\n",
      "           3       0.18      0.17      0.18       371\n",
      "           4       0.08      0.08      0.08       182\n",
      "           5       0.07      0.07      0.07        75\n",
      "           6       0.05      0.04      0.04        26\n",
      "\n",
      "    accuracy                           0.21      2000\n",
      "   macro avg       0.15      0.15      0.15      2000\n",
      "weighted avg       0.21      0.21      0.21      2000\n",
      "\n",
      "F2 Score: 0.20954849775199028\n"
     ]
    }
   ],
   "source": [
    "baseline_classifier_grade = DummyClassifier(strategy='stratified')\n",
    "\n",
    "baseline_classifier_grade.fit(X_train_grade_p, y_train_grade_p)\n",
    "\n",
    "baseline_preds_grade = baseline_classifier_grade.predict(X_test_grade_p)\n",
    "\n",
    "print(\"Baseline Classification Report:\\n\", classification_report(y_test_grade_p, \n",
    "                                                                 baseline_preds_grade, \n",
    "                                                                 zero_division=1))\n",
    "\n",
    "f2 = fbeta_score(y_test_grade_p, baseline_preds_grade, beta=2, \n",
    "                 average='weighted')  \n",
    "print(f\"F2 Score: {f2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204edbc-c4e4-4728-bc84-2c5cb1541538",
   "metadata": {},
   "source": [
    "## 2.3. Baseline Model for Sub-Grade Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "d57c14a1-e41f-4c20-8499-531a8976a183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Squared Error for Sub-Grade Prediction: 45.411275390625\n",
      "R-squared (R2): -4.088001984259293e-06\n"
     ]
    }
   ],
   "source": [
    "baseline_regressor_sub_grade = DummyRegressor(strategy='mean')\n",
    "\n",
    "baseline_regressor_sub_grade.fit(X_train_sub_grade_p, y_train_sub_grade_p)\n",
    "\n",
    "baseline_preds_sub_grade = baseline_regressor_sub_grade.predict(X_test_sub_grade_p)\n",
    "print(\"Baseline Mean Squared Error for Sub-Grade Prediction:\", mean_squared_error(y_test_sub_grade_p, \n",
    "                                                                                  baseline_preds_sub_grade))\n",
    "\n",
    "r2 = r2_score(y_test_sub_grade_p, baseline_preds_sub_grade)\n",
    "print(f'R-squared (R2): {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2963ebdd-952e-498d-b622-bd8cadcdba7e",
   "metadata": {},
   "source": [
    "## 2.4. Baseline Model for Interest Rate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "89763600-59a3-46d6-a36c-b0b23254416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Squared Error for Interest Rate Prediction: 0.039398666237955716\n",
      "R-squared (R2): -9.085056114099821e-05\n"
     ]
    }
   ],
   "source": [
    "baseline_regressor_int_rate = DummyRegressor(strategy='mean')\n",
    "\n",
    "baseline_regressor_int_rate.fit(X_train_int_rate_p, y_train_int_rate_p)\n",
    "\n",
    "baseline_preds_int_rate = baseline_regressor_int_rate.predict(X_test_int_rate_p)\n",
    "print(\"Baseline Mean Squared Error for Interest Rate Prediction:\", mean_squared_error(y_test_int_rate_p, \n",
    "                                                                                      baseline_preds_int_rate))\n",
    "r2 = r2_score(y_test_int_rate_p, baseline_preds_int_rate)\n",
    "print(f'R-squared (R2): {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7fe215-7b65-4c17-985f-4f6ed2e69e35",
   "metadata": {},
   "source": [
    "# 3. Building and tuning ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd441475-597e-4196-9ee7-03187899d830",
   "metadata": {},
   "source": [
    "## 3.1. Grid search for each modeling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d133a6d4-2082-47e1-a717-e316c7fed04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_scorer(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    return r2_score(y_true, y_pred, multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ed04ff2c-b579-48bb-9dfd-678884a590ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(models, params, X_train, y_train, scoring):\n",
    "    results = []\n",
    "    algo_best_params = {}\n",
    "\n",
    "    for model, param in zip(models, params):\n",
    "        pipe = Pipeline(steps=[('classifier', model)])\n",
    "        search = GridSearchCV(pipe, param, cv=5, scoring=scoring, refit=scoring)\n",
    "        search.fit(X_train, y_train)\n",
    "        print(f\"Algorithm: {model}\")\n",
    "        print(f'Best parameter: {search.best_params_}')\n",
    "        print(f\"Best {scoring}: {search.best_score_:.3f}\")\n",
    "        best_score = search.cv_results_['mean_test_score'][search.best_index_]\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        best_pipe = search.best_estimator_\n",
    "        algo_best_params[model.__class__.__name__] = search.best_params_\n",
    "\n",
    "        results.append({\n",
    "            'model': model.__class__.__name__,\n",
    "            scoring: best_score,\n",
    "            'std': search.cv_results_['std_test_score'][search.best_index_],\n",
    "        })\n",
    "\n",
    "    return results, algo_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "3ef7f919-553e-46e6-a6e1-62a065eb10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = [\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42), \n",
    "    RandomForestClassifier(random_state=42),\n",
    "    XGBClassifier(random_state=42),\n",
    "    LGBMClassifier(verbose=-1, random_state=42),\n",
    "]\n",
    "\n",
    "classification_params = [\n",
    "    {'classifier__C': [0.1, 0.5, 1, 10, 100],  # LogisticRegression\n",
    "     'classifier__penalty': ['l2']},\n",
    "    \n",
    "    {'classifier__n_estimators': [100, 200, 500],  # RandomForestClassifier\n",
    "     'classifier__max_depth': [5, 8, 15],\n",
    "     'classifier__criterion': ['gini', 'entropy']},\n",
    "     \n",
    "     {'classifier__learning_rate': [0.05, 0.1, 0.2],  # XGBClassifier   \n",
    "     'classifier__max_depth': [5, 8, 12],\n",
    "     'classifier__colsample_bytree': [0.5, 0.8, 1.0]},\n",
    "     \n",
    "     {'classifier__num_leaves': [10, 15, 31],  #LGBMClassifier\n",
    "     'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "     'classifier__n_estimators': [100, 150, 200]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9905fc80-5276-454b-a8ad-bca2fab567be",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = [\n",
    "    RandomForestRegressor(random_state=42), \n",
    "    XGBRegressor(random_state=42),\n",
    "    LGBMRegressor(verbose=-1, random_state=42),\n",
    "    CatBoostClassifier(verbose=0, random_state=42),\n",
    "    SVC(random_state=42),\n",
    "]\n",
    "\n",
    "regression_params = [\n",
    "  {'classifier__n_estimators': [50, 100, 200, 300], # RandomForestRegressor\n",
    "   'classifier__max_depth': [None, 5, 10, 20],\n",
    "   'classifier__min_samples_split': [2, 5, 7, 10],\n",
    "   'classifier__max_features': [None, 'sqrt', 'log2', 0.1, 0.5, 0.9]}, \n",
    "   \n",
    "  {'classifier__learning_rate': [0.05, 0.1, 0.2],  # XGBRegressor   \n",
    "   'classifier__max_depth': [5, 8, 12],\n",
    "   'classifier__colsample_bytree': [0.5, 0.8, 1.0]},\n",
    "     \n",
    "   {'classifier__num_leaves': [10, 15, 31],  # LGBMRegressor\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'classifier__n_estimators': [100, 150, 200]},\n",
    "\n",
    "   {'classifier__iterations': [50, 100, 200], # CatBoostClassifier\n",
    "    'classifier__learning_rate': [0.1, 0.5],\n",
    "    'classifier__depth': [3, 5, 10]}, \n",
    "\n",
    "    {'classifier__C': [0.1, 1, 10],  # SVC\n",
    "     'classifier__kernel': ['linear', 'rbf'],\n",
    "     'classifier__gamma': ['scale', 'auto']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "26630758-dde1-43a7-8446-e82f74e94148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "multi_output_models = [\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    XGBRegressor(random_state=42),\n",
    "    LGBMRegressor(verbose=-1, random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "]\n",
    "\n",
    "multi_output_params = [\n",
    "    {'classifier__max_features': ['sqrt', 'log2', None],  # RandomForestRegressor\n",
    "     'classifier__max_depth': [5, 8, 15],\n",
    "     'classifier__n_estimators': [100, 200, 500]},\n",
    "\n",
    "    {'classifier__learning_rate': [0.05, 0.1, 0.2],  # XGBRegressor\n",
    "     'classifier__max_depth': [5, 8, 12],\n",
    "     'classifier__colsample_bytree': [0.5, 0.8, 1.0]},\n",
    "\n",
    "    {'classifier__num_leaves': [10, 15, 31],  # LGBMRegressor\n",
    "     'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "     'classifier__n_estimators': [100, 150, 200]},\n",
    "\n",
    "    {'classifier__n_estimators': [50, 100, 150],  # GradientBoostingRegressor\n",
    "     'classifier__learning_rate': [0.01, 0.5, 0.1, 0.2],\n",
    "     'classifier__max_depth': [3, 4, 5]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "8964e511-296b-41b8-8e1d-41f83350594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: LogisticRegression(max_iter=1000, random_state=42)\n",
      "Best parameter: {'classifier__C': 1, 'classifier__penalty': 'l2'}\n",
      "Best roc_auc: 0.949\n",
      "------------------------------\n",
      "Algorithm: RandomForestClassifier(random_state=42)\n",
      "Best parameter: {'classifier__criterion': 'entropy', 'classifier__max_depth': 15, 'classifier__n_estimators': 500}\n",
      "Best roc_auc: 0.943\n",
      "------------------------------\n",
      "Algorithm: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=42, ...)\n",
      "Best parameter: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.05, 'classifier__max_depth': 5}\n",
      "Best roc_auc: 0.950\n",
      "------------------------------\n",
      "Algorithm: LGBMClassifier(random_state=42, verbose=-1)\n",
      "Best parameter: {'classifier__learning_rate': 0.05, 'classifier__n_estimators': 100, 'classifier__num_leaves': 10}\n",
      "Best roc_auc: 0.950\n",
      "------------------------------\n",
      "Results for loan_status: \n",
      "[{'model': 'LogisticRegression', 'roc_auc': 0.9487631249999999, 'std': 0.00506076885910757}, {'model': 'RandomForestClassifier', 'roc_auc': 0.943444375, 'std': 0.004371665090564769}, {'model': 'XGBClassifier', 'roc_auc': 0.9502128125, 'std': 0.004631853494755086}, {'model': 'LGBMClassifier', 'roc_auc': 0.950426875, 'std': 0.004941515885641462}]\n",
      "Best Params: \n",
      "{'LogisticRegression': {'classifier__C': 1, 'classifier__penalty': 'l2'}, 'RandomForestClassifier': {'classifier__criterion': 'entropy', 'classifier__max_depth': 15, 'classifier__n_estimators': 500}, 'XGBClassifier': {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.05, 'classifier__max_depth': 5}, 'LGBMClassifier': {'classifier__learning_rate': 0.05, 'classifier__n_estimators': 100, 'classifier__num_leaves': 10}}\n",
      "------------------------------\n",
      "Algorithm: RandomForestRegressor(random_state=42)\n",
      "Best parameter: {'classifier__max_depth': 20, 'classifier__max_features': 0.5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}\n",
      "Best r2: 0.498\n",
      "------------------------------\n",
      "Algorithm: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n",
      "Best parameter: {'classifier__colsample_bytree': 0.5, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5}\n",
      "Best r2: 0.540\n",
      "------------------------------\n",
      "Algorithm: LGBMRegressor(random_state=42, verbose=-1)\n",
      "Best parameter: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200, 'classifier__num_leaves': 10}\n",
      "Best r2: 0.547\n",
      "------------------------------\n",
      "Algorithm: <catboost.core.CatBoostClassifier object at 0x15ace5660>\n",
      "Best parameter: {'classifier__depth': 5, 'classifier__iterations': 200, 'classifier__learning_rate': 0.1}\n",
      "Best r2: 0.414\n",
      "------------------------------\n",
      "Algorithm: SVC(random_state=42)\n",
      "Best parameter: {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}\n",
      "Best r2: 0.388\n",
      "------------------------------\n",
      "Results for grade: \n",
      "[{'model': 'RandomForestRegressor', 'r2': 0.4982511036217878, 'std': 0.018921922802538262}, {'model': 'XGBRegressor', 'r2': 0.5404515411522397, 'std': 0.021407389183681687}, {'model': 'LGBMRegressor', 'r2': 0.5468673570167105, 'std': 0.02156175282645323}, {'model': 'CatBoostClassifier', 'r2': 0.41403642913779715, 'std': 0.01755790857482911}, {'model': 'SVC', 'r2': 0.38764279894223275, 'std': 0.018254200274517355}]\n",
      "Best Params: \n",
      "{'RandomForestRegressor': {'classifier__max_depth': 20, 'classifier__max_features': 0.5, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 300}, 'XGBRegressor': {'classifier__colsample_bytree': 0.5, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5}, 'LGBMRegressor': {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200, 'classifier__num_leaves': 10}, 'CatBoostClassifier': {'classifier__depth': 5, 'classifier__iterations': 200, 'classifier__learning_rate': 0.1}, 'SVC': {'classifier__C': 10, 'classifier__gamma': 'scale', 'classifier__kernel': 'linear'}}\n",
      "------------------------------\n",
      "Algorithm: RandomForestRegressor(random_state=42)\n",
      "Best parameter: {'classifier__max_depth': 15, 'classifier__max_features': None, 'classifier__n_estimators': 500}\n",
      "Best r2: 0.518\n",
      "------------------------------\n",
      "Algorithm: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n",
      "Best parameter: {'classifier__colsample_bytree': 0.5, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5}\n",
      "Best r2: 0.570\n",
      "------------------------------\n",
      "Algorithm: LGBMRegressor(random_state=42, verbose=-1)\n",
      "Best parameter: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200, 'classifier__num_leaves': 10}\n",
      "Best r2: 0.576\n",
      "------------------------------\n",
      "Algorithm: GradientBoostingRegressor(random_state=42)\n",
      "Best parameter: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 150}\n",
      "Best r2: 0.575\n",
      "------------------------------\n",
      "Results for sub_grade_int_rate: \n",
      "[{'model': 'RandomForestRegressor', 'r2': 0.517804504469704, 'std': 0.013151484797780898}, {'model': 'XGBRegressor', 'r2': 0.5698730007878186, 'std': 0.01186451210169603}, {'model': 'LGBMRegressor', 'r2': 0.5762407199321505, 'std': 0.013435715048350047}, {'model': 'GradientBoostingRegressor', 'r2': 0.5746044687468453, 'std': 0.01233350733979371}]\n",
      "Best Params: \n",
      "{'RandomForestRegressor': {'classifier__max_depth': 15, 'classifier__max_features': None, 'classifier__n_estimators': 500}, 'XGBRegressor': {'classifier__colsample_bytree': 0.5, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5}, 'LGBMRegressor': {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200, 'classifier__num_leaves': 10}, 'GradientBoostingRegressor': {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 150}}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "target_columns = ['loan_status', 'grade', 'sub_grade_int_rate']\n",
    "\n",
    "for target in target_columns:\n",
    "\n",
    "  if target == 'loan_status':\n",
    "      models = classification_models  \n",
    "      params = classification_params\n",
    "      scoring = 'roc_auc'\n",
    "      y_train = y_train_status_p\n",
    "      X_train = X_train_status_p\n",
    "\n",
    "  elif target == 'grade':\n",
    "      models = regression_models\n",
    "      params = regression_params \n",
    "      scoring = 'r2'\n",
    "      y_train = y_train_grade_p\n",
    "      X_train = X_train_grade_p\n",
    "\n",
    "  else:\n",
    "      models = multi_output_models\n",
    "      params = multi_output_params\n",
    "      scoring = 'r2'\n",
    "      y_train = y_train_sub_grade_p\n",
    "      X_train = X_train_sub_grade_p\n",
    "\n",
    "  results, best_params = model_selection(\n",
    "      models=models,\n",
    "      params=params,   \n",
    "      X_train=X_train,\n",
    "      y_train=y_train.ravel(), \n",
    "      scoring=scoring)\n",
    "\n",
    "  print(f\"Results for {target}: \") \n",
    "  print(results)\n",
    "  print(\"Best Params: \")\n",
    "  print(best_params)\n",
    "  print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c04230-6d27-457a-a642-1cece638d923",
   "metadata": {},
   "source": [
    "## 3.2. Automated ML modeling with TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "37361ad1-4c0f-402a-b534-e843609f7673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.95077578125\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9508946875\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9508946875\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9508946875\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9509232812499999\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.9509232812499999\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.9509549999999999\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.9509549999999999\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.9509549999999999\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.9510265625000001\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.1, max_depth=1, min_child_weight=15, n_estimators=100, n_jobs=1, subsample=0.35000000000000003, verbosity=0)\n",
      "0.9556045\n"
     ]
    }
   ],
   "source": [
    "automl_classifier = TPOTClassifier(generations=10, population_size=20, \n",
    "                                    verbosity=2, scoring='roc_auc', cv=5)\n",
    "                                    \n",
    "automl_classifier.fit(X_train_status_p, y_train_status_p.ravel())\n",
    "print(automl_classifier.score(X_test_status_p, y_test_status_p.ravel()))\n",
    "automl_classifier.export('tpot_loan_status.py')\n",
    "\n",
    "joblib.dump(automl_classifier.fitted_pipeline_, 'tpot_loan_status_model.joblib')\n",
    "\n",
    "with open('tpot_loan_status_model.pkl', 'wb') as file:\n",
    "    pickle.dump(automl_classifier.fitted_pipeline_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "257e015e-472f-4190-a028-6ac29c64e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.5280626673578872\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.533929719294215\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.5407388132328148\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.5407388132328148\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.5417150798566631\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.5417150798566631\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.5417354204272579\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.5417354204272579\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.5431707864591775\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.5431707864591775\n",
      "\n",
      "Best pipeline: ElasticNetCV(RidgeCV(XGBRegressor(input_matrix, learning_rate=0.5, max_depth=1, min_child_weight=20, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.9000000000000001, verbosity=0)), l1_ratio=0.4, tol=0.1)\n",
      "0.5079595895945581\n"
     ]
    }
   ],
   "source": [
    "automl_regressor = TPOTRegressor(generations=10, population_size=20, \n",
    "                               verbosity=2, scoring='r2', cv=5)\n",
    "                               \n",
    "automl_regressor.fit(X_train_grade_p, y_train_grade_p.ravel())  \n",
    "print(automl_regressor.score(X_test_grade_p, y_test_grade_p.ravel()))\n",
    "automl_regressor.export('tpot_loan_grade.py')\n",
    "\n",
    "joblib.dump(automl_regressor.fitted_pipeline_, 'tpot_loan_grade_model.joblib')\n",
    "\n",
    "with open('tpot_loan_grade_model.pkl', 'wb') as file:\n",
    "    pickle.dump(automl_regressor.fitted_pipeline_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "daf5f1ef-5d15-42c3-8be4-729b3df0d3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/240 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.5612972553776866\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.5638527802585593\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.5690860595739439\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.5702143948886012\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.5702143948886012\n",
      "\n",
      "Best pipeline: XGBRegressor(input_matrix, learning_rate=0.1, max_depth=5, min_child_weight=19, n_estimators=100, n_jobs=1, objective=reg:squarederror, subsample=0.7000000000000001, verbosity=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/240 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -0.0010100194342258727\n",
      "\n",
      "Generation 2 - Current best internal CV score: -0.0010100194342258727\n",
      "\n",
      "Generation 3 - Current best internal CV score: -0.0008060877985545556\n",
      "\n",
      "Generation 4 - Current best internal CV score: -0.0008060877985545556\n",
      "\n",
      "Generation 5 - Current best internal CV score: -0.0008060877985545556\n",
      "\n",
      "Best pipeline: ElasticNetCV(MinMaxScaler(input_matrix), l1_ratio=0.6000000000000001, tol=0.01)\n",
      "0.3611088553583944\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "automl_regressor_multi = TPOTRegressor(generations=5, population_size=40, \n",
    "                                       verbosity=2, scoring='r2', cv=5)\n",
    "multioutput_regressor = MultiOutputRegressor(automl_regressor_multi)\n",
    "\n",
    "multioutput_regressor.fit(X_train_sub_grade_p, np.column_stack((y_train_sub_grade_p.ravel(), \n",
    "                                                                y_train_int_rate_p.ravel(),\n",
    "                                                               )))\n",
    "print(multioutput_regressor.score(X_train_sub_grade_p, np.column_stack((y_train_sub_grade_p.ravel(), \n",
    "                                                                        y_train_int_rate_p.ravel(),\n",
    "                                                                       ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7bdad621-12d0-419e-9595-8fde3ce6913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tpot_subgrade_int_rate_model.joblib']"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyXGBRegressor(XGBRegressor, BaseEstimator):\n",
    "    def __reduce__(self):\n",
    "        return super().__reduce__()\n",
    "\n",
    "custom_xgb = MyXGBRegressor()\n",
    "\n",
    "joblib.dump(custom_xgb, 'tpot_subgrade_int_rate_model.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf500e-1560-4ff2-8c86-9cff086e945c",
   "metadata": {},
   "source": [
    "## 3.3. Improving the top-performing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f5f07d-a8f8-45a0-ae67-9d623a2cd9a5",
   "metadata": {},
   "source": [
    "### 3.3.1. Loan status prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "7a6fcead-fc3f-4fc4-983a-d94d902faf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fbeta_score(y_true, y_pred, beta):\n",
    "    return fbeta_score(y_true, y_pred, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7691ccd6-fd25-40d6-9bfc-1acde1295f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "{'C': 1.5, 'class_weight': None, 'solver': 'lbfgs'}\n",
      "Recall: 0.911\n",
      "F-beta(2) Score: 0.906\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.89      1000\n",
      "         1.0       0.89      0.91      0.90      1000\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.90      0.90      0.90      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>882</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>89</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          882          118\n",
       "Actual 1           89          911"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "fbeta_scorer = make_scorer(custom_fbeta_score, beta=2)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, penalty='l2', random_state=42)\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 0.5, 1, 1.5, 2, 5, 10],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(lr, param_grid, \n",
    "                     scoring=fbeta_scorer, \n",
    "                     cv=5, verbose=True, \n",
    "                     n_jobs=-1)\n",
    "gs_lr.fit(X_train_status_p, y_train_status_p.ravel())\n",
    "print(gs_lr.best_params_)\n",
    "y_pred = gs_lr.predict(X_test_status_p)\n",
    "print(\"Recall:\", recall_score(y_test_status_p.ravel(), y_pred))\n",
    "fbeta = fbeta_score(y_test_status_p.ravel(), y_pred, beta=2)\n",
    "print(f\"F-beta({2}) Score: {fbeta:.3f}\")\n",
    "class_report = classification_report(y_test_status_p.ravel(), y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "cm = confusion_matrix(y_test_status_p.ravel(), y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "                     columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "d2a2d8af-544a-4a87-942b-efc7c79de306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9\n",
      "F-beta(2) Score: 0.901\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.91      0.90      1000\n",
      "         1.0       0.91      0.90      0.90      1000\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.90      0.90      0.90      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>907</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>100</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0          907           93\n",
       "Actual 1          100          900"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr_status = LogisticRegression(**gs_lr.best_params_, \n",
    "                                    max_iter=1000, \n",
    "                                    penalty='l2',\n",
    "                                    random_state=42)\n",
    "best_lr_status.fit(X_train_status_p, y_train_status_p.ravel())\n",
    "\n",
    "y_pred = best_lr_status.predict(X_test_status_p)\n",
    "print(\"Recall:\", recall_score(y_test_status_p.ravel(), y_pred))\n",
    "fbeta = fbeta_score(y_test_status_p.ravel(), y_pred, beta=2)\n",
    "print(f\"F-beta({2}) Score: {fbeta:.3f}\")\n",
    "class_report = classification_report(y_test_status_p.ravel(), y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "cm = confusion_matrix(y_test_status_p.ravel(), y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "                     columns=['Predicted 0', 'Predicted 1'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "e8c9ff24-97a3-47b9-823c-c992d6fad630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_status_classifier.joblib']"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_lr_status, 'loan_status_classifier.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a1a78-111f-46b1-9a1a-ac3533dea4f6",
   "metadata": {},
   "source": [
    "### 3.3.2. Grade prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "b80577aa-266b-4620-83f3-884b9353c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 300, 'num_leaves': 5}\n",
      "R2 Score: 0.555\n",
      "Mean Squared Error: 0.812\n",
      "Mean Absolute Error: 0.705\n",
      "Explained Variance Score: 0.555\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'num_leaves': [5, 10, 15]\n",
    "}\n",
    "\n",
    "lgbm = LGBMRegressor(verbose=-1)\n",
    "\n",
    "gs_lgbm = GridSearchCV(lgbm, param_grid,\n",
    "                       scoring='r2', \n",
    "                       cv=5, verbose=True,\n",
    "                       n_jobs=-1)\n",
    "gs_lgbm.fit(X_train_grade_p, y_train_grade_p)  \n",
    "\n",
    "print(gs_lgbm.best_params_)\n",
    "\n",
    "y_pred = gs_lgbm.predict(X_test_grade_p)  \n",
    "\n",
    "r2 = r2_score(y_test_grade_p, y_pred)\n",
    "print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_grade_p, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.3f}')\n",
    "\n",
    "mae = mean_absolute_error(y_test_grade_p, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.3f}')\n",
    "\n",
    "evs = explained_variance_score(y_test_grade_p, y_pred)\n",
    "print(f'Explained Variance Score: {evs:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "1a246ee3-fef1-462c-917d-bf6be1fbda9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.555\n",
      "Mean Squared Error: 0.812\n",
      "Mean Absolute Error: 0.705\n",
      "Explained Variance Score: 0.555\n"
     ]
    }
   ],
   "source": [
    "best_lgbm_grade = LGBMRegressor(verbose=-1, **gs_lgbm.best_params_)\n",
    "best_lgbm_grade.fit(X_train_grade_p, y_train_grade_p)\n",
    "\n",
    "y_pred = best_lgbm_grade.predict(X_test_grade_p)  \n",
    "\n",
    "r2 = r2_score(y_test_grade_p, y_pred)\n",
    "print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_grade_p, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.3f}')\n",
    "\n",
    "mae = mean_absolute_error(y_test_grade_p, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.3f}')\n",
    "\n",
    "evs = explained_variance_score(y_test_grade_p, y_pred)\n",
    "print(f'Explained Variance Score: {evs:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "6e7dca38-5f81-4f18-b35c-8b22ea0d734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade_regressor.joblib']"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_lgbm_grade, 'grade_regressor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa423da7-a14a-465c-a917-e3f34707bc3a",
   "metadata": {},
   "source": [
    "### 3.3.3. Sub-grade and interest rate prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "e35eab82-04fb-442d-bb57-2946dcdefbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models_2 = [\n",
    "    RandomForestRegressor(random_state=42), \n",
    "    XGBRegressor(random_state=42),\n",
    "    LGBMRegressor(verbose=-1, random_state=42),\n",
    "]\n",
    "\n",
    "regression_params_2 = [\n",
    "  {'classifier__n_estimators': [50, 100, 200, 300], # RandomForestRegressor\n",
    "   'classifier__max_depth': [None, 5, 10, 20],\n",
    "   'classifier__min_samples_split': [2, 5, 7, 10],\n",
    "   'classifier__max_features': [None, 'sqrt', 'log2', 0.1, 0.5, 0.9]}, \n",
    "   \n",
    "  {'classifier__learning_rate': [0.05, 0.1, 0.2],  # XGBRegressor   \n",
    "   'classifier__max_depth': [5, 8, 12],\n",
    "   'classifier__colsample_bytree': [0.5, 0.8, 1.0]},\n",
    "     \n",
    "   {'classifier__num_leaves': [10, 15, 31],  # LGBMRegressor\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'classifier__n_estimators': [100, 150, 200]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "14a6d241-7cbb-44ee-9537-3311fa31b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def random_model_selection(models, params, X_train, y_train, \n",
    "                           scoring, n_iter=10, random_state=42):\n",
    "    results = []\n",
    "    algo_best_params = {}\n",
    "\n",
    "    for model, param in zip(models, params):\n",
    "        pipe = Pipeline(steps=[('classifier', model)])\n",
    "        search = RandomizedSearchCV(pipe, param_distributions=param, \n",
    "                                    n_iter=n_iter, cv=5, scoring=scoring, \n",
    "                                    refit=scoring, random_state=random_state)\n",
    "        search.fit(X_train, y_train)\n",
    "        print(f\"Algorithm: {model}\")\n",
    "        print(f'Best parameter: {search.best_params_}')\n",
    "        print(f\"Best {scoring}: {search.best_score_:.3f}\")\n",
    "        best_score = search.cv_results_['mean_test_score'][search.best_index_]\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        best_pipe = search.best_estimator_\n",
    "        algo_best_params[model.__class__.__name__] = search.best_params_\n",
    "\n",
    "        results.append({\n",
    "            'model': model.__class__.__name__,\n",
    "            scoring: best_score,\n",
    "            'std': search.cv_results_['std_test_score'][search.best_index_],\n",
    "        })\n",
    "\n",
    "    return results, algo_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130addfb-5f93-41dc-a2e4-6c5db69e9ef6",
   "metadata": {},
   "source": [
    "Sub-grade prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "0dec7fc2-a55b-4edf-a936-74db551b7126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: RandomForestRegressor(random_state=42)\n",
      "Best parameter: {'classifier__n_estimators': 300, 'classifier__min_samples_split': 2, 'classifier__max_features': 0.5, 'classifier__max_depth': 20}\n",
      "Best r2: 0.521\n",
      "------------------------------\n",
      "Algorithm: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n",
      "Best parameter: {'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.8}\n",
      "Best r2: 0.568\n",
      "------------------------------\n",
      "Algorithm: LGBMRegressor(random_state=42, verbose=-1)\n",
      "Best parameter: {'classifier__num_leaves': 15, 'classifier__n_estimators': 150, 'classifier__learning_rate': 0.1}\n",
      "Best r2: 0.576\n",
      "------------------------------\n",
      "[{'model': 'RandomForestRegressor', 'r2': 0.5205244948072395, 'std': 0.01388462802319921}, {'model': 'XGBRegressor', 'r2': 0.5683601537183494, 'std': 0.01056652312998511}, {'model': 'LGBMRegressor', 'r2': 0.5761833769800917, 'std': 0.012400250645714726}]\n",
      "Best Params: \n",
      "{'RandomForestRegressor': {'classifier__n_estimators': 300, 'classifier__min_samples_split': 2, 'classifier__max_features': 0.5, 'classifier__max_depth': 20}, 'XGBRegressor': {'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.8}, 'LGBMRegressor': {'classifier__num_leaves': 15, 'classifier__n_estimators': 150, 'classifier__learning_rate': 0.1}}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "results, best_params = random_model_selection(\n",
    "  models=regression_models_2,\n",
    "  params=regression_params_2,   \n",
    "  X_train=X_train_sub_grade_p,\n",
    "  y_train=y_train_sub_grade_p.ravel(), \n",
    "  scoring='r2')\n",
    "\n",
    "print(results)\n",
    "print(\"Best Params: \")\n",
    "print(best_params)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "80f526c3-ef2b-44aa-b181-3e1e1c99577a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: LGBMRegressor\n",
      "R2 Score: 0.575322\n",
      "Standard Deviation: 0.011019\n",
      "Best Hyperparameters: {'classifier__num_leaves': 15, 'classifier__n_estimators': 150, 'classifier__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'classifier__num_leaves': np.arange(10, 20, 1),\n",
    "    'classifier__n_estimators': [100, 150, 200, 250],\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "lgbm_model = LGBMRegressor(verbose=-1, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('classifier', lgbm_model)])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe, param_distributions=best_params, \n",
    "                                   n_iter=10, cv=5, scoring='r2', n_jobs=-1, \n",
    "                                   random_state=42)\n",
    "random_search.fit(X_train_sub_grade_p, y_train_sub_grade_p)\n",
    "\n",
    "print(f\"Best Estimator: LGBMRegressor\")\n",
    "print(f\"R2 Score: {random_search.best_score_:.6f}\")\n",
    "print(f\"Standard Deviation: {random_search.cv_results_['std_test_score'][random_search.best_index_]:.6f}\")\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "93fe35b2-4e67-4b7a-803f-7d971e813dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.579\n",
      "Mean Squared Error: 19.096\n",
      "Mean Absolute Error: 3.380\n",
      "Explained Variance Score: 0.580\n"
     ]
    }
   ],
   "source": [
    "best_lgbm_sub_grade = LGBMRegressor(verbose=-1, \n",
    "                                    random_state=42,\n",
    "                                    **random_search.best_params_)\n",
    "best_lgbm_sub_grade.fit(X_train_sub_grade_p, y_train_sub_grade_p)\n",
    "\n",
    "y_pred = best_lgbm_sub_grade.predict(X_test_sub_grade_p)  \n",
    "\n",
    "r2 = r2_score(y_test_sub_grade_p, y_pred)\n",
    "print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_sub_grade_p, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.3f}')\n",
    "\n",
    "mae = mean_absolute_error(y_test_sub_grade_p, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.3f}')\n",
    "\n",
    "evs = explained_variance_score(y_test_sub_grade_p, y_pred)\n",
    "print(f'Explained Variance Score: {evs:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "6aef6a6e-6ba0-496b-919a-29657317e649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub_grade_regressor.joblib']"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_lgbm_sub_grade, 'sub_grade_regressor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357414a1-8f84-4ab4-bc7e-eb9a220dea9e",
   "metadata": {},
   "source": [
    "Interest rate prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "38ce0f07-e541-46c5-b9f1-2e00a9e40125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: RandomForestRegressor(random_state=42)\n",
      "Best parameter: {'classifier__n_estimators': 300, 'classifier__min_samples_split': 2, 'classifier__max_features': 0.5, 'classifier__max_depth': 20}\n",
      "Best r2: 0.491\n",
      "------------------------------\n",
      "Algorithm: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n",
      "Best parameter: {'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.8}\n",
      "Best r2: 0.534\n",
      "------------------------------\n",
      "Algorithm: LGBMRegressor(random_state=42, verbose=-1)\n",
      "Best parameter: {'classifier__num_leaves': 10, 'classifier__n_estimators': 150, 'classifier__learning_rate': 0.1}\n",
      "Best r2: 0.540\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[476], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_model_selection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregression_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregression_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_int_rate_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_int_rate_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Params: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[472], line 13\u001b[0m, in \u001b[0;36mrandom_model_selection\u001b[0;34m(models, params, X_train, y_train, scoring, n_iter, random_state)\u001b[0m\n\u001b[1;32m      9\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, model)])\n\u001b[1;32m     10\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(pipe, param_distributions\u001b[38;5;241m=\u001b[39mparam, \n\u001b[1;32m     11\u001b[0m                             n_iter\u001b[38;5;241m=\u001b[39mn_iter, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mscoring, \n\u001b[1;32m     12\u001b[0m                             refit\u001b[38;5;241m=\u001b[39mscoring, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m---> 13\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlgorithm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/catboost/core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5098\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5100\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5101\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5102\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/Projects/TuringCollege/M3_S3_Project/venv/lib/python3.10/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1724\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results, best_params = random_model_selection(\n",
    "  models=regression_models,\n",
    "  params=regression_params,   \n",
    "  X_train=X_train_int_rate_p,\n",
    "  y_train=y_train_int_rate_p.ravel(), \n",
    "  scoring='r2')\n",
    "\n",
    "print(results)\n",
    "print(\"Best Params: \")\n",
    "print(best_params)\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "eb2e201a-5d35-46bd-a232-bb2b3b7e93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: LGBMRegressor\n",
      "R2 Score: 0.537355\n",
      "Standard Deviation: 0.004124\n",
      "Best Hyperparameters: {'classifier__num_leaves': 9, 'classifier__n_estimators': 150, 'classifier__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'classifier__num_leaves': np.arange(7, 15, 1),\n",
    "    'classifier__n_estimators': [100, 150, 200, 250],\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "lgbm_model = LGBMRegressor(verbose=-1, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('classifier', lgbm_model)])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipe, param_distributions=best_params, \n",
    "                                   n_iter=10, cv=5, scoring='r2', n_jobs=-1, \n",
    "                                   random_state=42)\n",
    "random_search.fit(X_train_int_rate_p, y_train_int_rate_p.ravel())\n",
    "\n",
    "print(f\"Best Estimator: LGBMRegressor\")\n",
    "print(f\"R2 Score: {random_search.best_score_:.6f}\")\n",
    "print(f\"Standard Deviation: {random_search.cv_results_['std_test_score'][random_search.best_index_]:.6f}\")\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef913aab-51a3-4ff8-a6d1-b04c2465df38",
   "metadata": {},
   "source": [
    "The R2 could be better for predicting the interest rate. Let's see whether we could get some difference by applying PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "c21080c7-3e39-4550-87e0-735019d8162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: LGBMRegressor\n",
      "R2 Score: 0.454246\n",
      "Standard Deviation: 0.009875\n",
      "Best Hyperparameters: {'classifier__num_leaves': 9, 'classifier__n_estimators': 150, 'classifier__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'classifier__num_leaves': np.arange(7, 15, 1),\n",
    "    'classifier__n_estimators': [100, 150, 200, 250],\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "lgbm_model = LGBMRegressor(verbose=-1, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('pca', PCA(n_components=0.95)),  \n",
    "    ('classifier', lgbm_model)\n",
    "])\n",
    "random_search_pca = RandomizedSearchCV(pipe, param_distributions=best_params, \n",
    "                                   n_iter=10, cv=5, scoring='r2', n_jobs=-1, \n",
    "                                   random_state=42)\n",
    "random_search_pca.fit(X_train_int_rate_p, y_train_int_rate_p.ravel())\n",
    "\n",
    "print(f\"Best Estimator: LGBMRegressor\")\n",
    "print(f\"R2 Score: {random_search_pca.best_score_:.6f}\")\n",
    "print(f\"Standard Deviation: {random_search_pca.cv_results_['std_test_score'][random_search_pca.best_index_]:.6f}\")\n",
    "print(f\"Best Hyperparameters: {random_search_pca.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000b423-7b2d-4fbf-8eb0-adee2044825d",
   "metadata": {},
   "source": [
    "The result of the randomized grid search is worse with PCA, so we won't use it for our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "46bc4a0a-8129-4a45-ada3-86e04074ead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.537\n",
      "Mean Squared Error: 0.018\n",
      "Mean Absolute Error: 0.103\n",
      "Explained Variance Score: 0.537\n"
     ]
    }
   ],
   "source": [
    "best_lgbm_int_rate = LGBMRegressor(verbose=-1, \n",
    "                                   random_state=42,\n",
    "                                   num_leaves=9, \n",
    "                                   n_estimators=150, \n",
    "                                   learning_rate=0.1)\n",
    "best_lgbm_int_rate.fit(X_train_int_rate_p, y_train_int_rate_p.ravel())\n",
    "\n",
    "y_pred = best_lgbm_int_rate.predict(X_test_int_rate_p)  \n",
    "\n",
    "r2 = r2_score(y_test_int_rate_p, y_pred)\n",
    "print(f\"R2 Score: {r2:.3f}\")\n",
    "\n",
    "mse = mean_squared_error(y_test_int_rate_p, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.3f}')\n",
    "\n",
    "mae = mean_absolute_error(y_test_int_rate_p, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.3f}')\n",
    "\n",
    "evs = explained_variance_score(y_test_int_rate_p, y_pred)\n",
    "print(f'Explained Variance Score: {evs:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "0b20c6c3-8fe9-4873-9c07-cfaf83364b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['int_rate_regressor.joblib']"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_lgbm_int_rate, 'int_rate_regressor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c049d9-bafe-46d2-b602-10e2e3cc91fd",
   "metadata": {},
   "source": [
    "# 5. Deploying ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15810ca4-7354-4cda-a602-b155b9d46c9d",
   "metadata": {},
   "source": [
    "The code for the deployment is in the 'flask_app.py' file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5def4f3-9abd-4441-a64d-fd4d2e048d51",
   "metadata": {},
   "source": [
    "# 6. Conclusions and further improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd0dd93-4f7d-4e12-a5cf-ffb6bd1edff5",
   "metadata": {},
   "source": [
    "- We've managed to achieve a nice result for the loan status prediction (fully paid vs charged off) with the classification model.\n",
    "- For regression tasks, overall we got R2 around 55-58. These results need improvement. In further modeling we would like to try different data preprocessing and dimensionality reduction techniques, and also try out other regression algorithms to check whether this would improve the prediction quality.\n",
    "- In future work, we would like to use SHAP to explain the models. And we would like to incorporate SHAP force plots in the Flask App.\n",
    "- The preprocessing and grid search pipelines also need some improvement. It would be also useful to transfer reusable code to a separate .py file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
